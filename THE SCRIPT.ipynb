{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f33b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from xml.etree import ElementTree as Xet\n",
    "import csv\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "import requests\n",
    "#%pip install requests beautifulsoup4\n",
    "#%pip install lxml\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "#https://github.com/LaurenceRawlings/savify\n",
    "#%pip install -U savify\n",
    "from savify import Savify\n",
    "from savify.types import Type, Format, Quality\n",
    "from savify.utils import PathHolder\n",
    "from savify.logger import Logger\n",
    "\n",
    "#https://github.com/alexmercerind/youtube-search-python\n",
    "#%pip install youtube-search-python\n",
    "#import youtubesearchpython as yts\n",
    "\n",
    "#https://github.com/ytdl-org/youtube-dl#embedding-youtube-dl\n",
    "#https://stackoverflow.com/questions/32482230/how-to-set-up-default-download-location-in-youtube-dl\n",
    "import youtube_dl\n",
    "import os\n",
    "\n",
    "#unused\n",
    "#%pip install music-tag\n",
    "#%pip install pytube\n",
    "#from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f9818e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module 1: Playing with html pages\n",
    "#converts the xml page into a dataframe, filters based on watching/completed and also adds mal link in last column\n",
    "def MakeCSV(exportedxml):\n",
    "    xml = Xet.parse(exportedxml)\n",
    "    csvfile = open('mal_to_csv.csv','w',encoding='utf-8')\n",
    "    csvfile_writer = csv.writer(csvfile)\n",
    "    csvfile_writer.writerow(['AnimeTitle','ID','Status'])\n",
    "\n",
    "    for anime in xml.findall('anime'):\n",
    "        if(anime):\n",
    "            animename = anime.find('series_title')\n",
    "            animeid = anime.find('series_animedb_id')\n",
    "            animestatus = anime.find('my_status')\n",
    "            csv_line = [animename.text, animeid.text, animestatus.text]\n",
    "            csvfile_writer.writerow(csv_line)\n",
    "    csvfile.close()  \n",
    "\n",
    "    df = pd.read_csv('mal_to_csv.csv')\n",
    "    df2= df.dropna()\n",
    "    filters = ['Completed', 'Watching']\n",
    "    df3 = df2[df2['Status'].isin(['Completed', 'Watching'])].reset_index()\n",
    "    del df3['index']\n",
    "    def make_url(row):\n",
    "        return 'https://myanimelist.net/anime/' + str(row[1])\n",
    "    df3['URL'] = df3.apply(make_url, axis = 1)\n",
    "    return df3\n",
    "\n",
    "#this function gives the title, season and year of the anime as a list\n",
    "def AnimeAndSeason(entry_page):\n",
    "    title  = entry_page.title.text.replace('\\n', ' ').split(' - ')[0].strip()\n",
    "    links  = entry_page.select('span > a')\n",
    "    years  = range(1900,2050)\n",
    "    season = ''\n",
    "    year   = 1900\n",
    "    for row in links:\n",
    "        test = row.contents[0].split()\n",
    "        if len(test) == 2 and test[1].isdigit() and int(test[1]) in years:\n",
    "            season_info = test\n",
    "            season = season_info[0] + ' ' + season_info[1]\n",
    "            year = int(season_info[1])\n",
    "    return(title, season, year)\n",
    "\n",
    "#function below gives a lil bit fucked list of the category/song/artist for individual mal page\n",
    "def SongAndArtist(entry_page):\n",
    "    testing = entry_page.find_all('div', attrs={'class':'di-tc va-t'})\n",
    "    testing2 = entry_page.find_all('div', attrs={'class':'di-tc va-t borderDark pb4'})\n",
    "    testing3 = testing + testing2\n",
    "    SAAlist = []\n",
    "    for entry in testing3:\n",
    "        category = entry.h2\n",
    "        if type(category) == bs4.element.Tag: \n",
    "            category_name = category.contents\n",
    "            SAAlist.append(category_name)\n",
    "\n",
    "        song_td_set = entry.find_all('td', {'width':'84%'})\n",
    "        for song_td in song_td_set:\n",
    "            song_data = song_td.text.replace('\\n', ' ').strip()\n",
    "            row = song_data.split('\\xa0') #split song# and song-artist\n",
    "            for datas in row:\n",
    "                if ' by ' in datas:\n",
    "                    row2 = datas.split(' by ') #split song and artist\n",
    "                    data_entry = [row2[0].strip('\\\"'), row2[1]]  #join song, artist\n",
    "                    song_links = song_td.find_all('input')\n",
    "                    for link in song_links:\n",
    "                        somelink = link['value']\n",
    "                        if 'spotify' in somelink:\n",
    "                            data_entry.append(somelink)\n",
    "                    SAAlist.append(data_entry)\n",
    "    return SAAlist\n",
    "\n",
    "#this combines the previous 2 functions and gives a nice dataframe of each row having all the identifying factors of a song\n",
    "def CreateSongDF(entry_page):\n",
    "    aas = AnimeAndSeason(entry_page)\n",
    "    saa = SongAndArtist(entry_page)\n",
    "    if aas[0] == 'Gyo (GYO: Tokyo Fish Attack!)': saa[2][0] = 'End Theme'\n",
    "    \n",
    "    for line in saa:\n",
    "        if 'Opening Theme' in line: op_index = saa.index(line)\n",
    "        if 'Ending Theme' in line: ed_index = saa.index(line)\n",
    "                   \n",
    "    OP = []\n",
    "    category = saa[op_index][0]\n",
    "    for op in range(op_index+1,ed_index):\n",
    "        temp = saa[op]\n",
    "        temp.insert(0,category)\n",
    "        OP.append(temp)\n",
    "\n",
    "    ED = []\n",
    "    category = saa[ed_index][0]\n",
    "    for ed in range(ed_index+1,len(saa)):\n",
    "        temp = saa[ed]\n",
    "        temp.insert(0,category)\n",
    "        ED.append(temp)\n",
    "    \n",
    "    def Clean_Blanks(List, Length):\n",
    "        for item in List:\n",
    "            if len(item) != Length:\n",
    "                item.extend(' ')\n",
    "       \n",
    "    Clean_Blanks(ED, 4)\n",
    "    Clean_Blanks(OP, 4)\n",
    "    song_columns = ['category', 'songname', 'artist', 'link']\n",
    "    opdb = pd.DataFrame(OP, columns = song_columns)\n",
    "    eddb = pd.DataFrame(ED, columns = song_columns)\n",
    "    SongDB = pd.concat([opdb,eddb], axis = 0, ignore_index = True)\n",
    "    SongDB['status'] = ''\n",
    "    return SongDB\n",
    "\n",
    "#Module 2: Playing with internet for spotify and youtube links\n",
    "#this creates a new dataframe (withc columns as song metadata and a 'links' column) from the csv containing mal urls\n",
    "def GetSpotify(malcsv, start, length):\n",
    "    song_table = pd.read_csv(malcsv).reset_index()\n",
    "    song_table.drop(['Unnamed: 0', 'index'], inplace=True, axis=1)\n",
    "    song_table = song_table.iloc[range(start, start+length), :]\n",
    "    link_table = pd.DataFrame(columns = ['anime', 'season', 'year','category', 'songname', 'artist', 'link', 'status'])\n",
    "    for i in song_table.index:\n",
    "        anime_link = song_table.loc[i,'URL']\n",
    "        html       = requests.get(anime_link).text #type: ignore       \n",
    "        mal_page   = bs(html, 'lxml')  \n",
    "        aas        = AnimeAndSeason(mal_page)\n",
    "\n",
    "        song_subtable    = CreateSongDF(mal_page)\n",
    "        anime_subtable   = pd.DataFrame(columns=['anime', 'season', 'year'])\n",
    "        print(i, 'Fetching spotify links for', aas[0])\n",
    "\n",
    "        for i in range(0, len(song_subtable)):\n",
    "            anime_subtable.loc[i,'anime'], anime_subtable.loc[i,'season'],  anime_subtable.loc[i,'year']   = aas[0], aas[1], aas[2]\n",
    "        anime_subtable = pd.concat([anime_subtable, song_subtable], axis = 1)\n",
    "        anime_subtable.to_csv('sheet_w_spot.csv', mode = 'a', index = False, header = False)\n",
    "\n",
    "#function to make all entries in the databases valid filenames\n",
    "def ValidFile(txt):\n",
    "    filename = ''\n",
    "    if '...' in txt:\n",
    "        txt = txt.strip('...')\n",
    "    for i in txt:\n",
    "        if i not in '\\/*?<>|\"':\n",
    "            filename = filename + i\n",
    "        elif i in ':':\n",
    "            filename = filename + '-'\n",
    "        else:\n",
    "            filename = filename + '_'\n",
    "    return filename\n",
    "\n",
    "#Module 3: Playing with external libraries to download songs\n",
    "#downloads spotify links into nested folder properly\n",
    "def DownloadSpotify(sheet_with_spotify, dl_loc, start, end):\n",
    "    songset = sheet_with_spotify.iloc[start:end]\n",
    "    for i in songset.index:\n",
    "        if 'spotify' not in songset.loc[i,'link'] or songset.loc[i,'status'] == 'Downloaded': continue\n",
    "        #https://developer.spotify.com/dashboard/applications/f2d89a80d48e41e19e4263d5b3792c21 for api credentials\n",
    "        sp_link = songset.loc[i,'link']\n",
    "        year    = str(songset.loc[i,'year'])\n",
    "        season  = str(songset.loc[i,'season'])\n",
    "        oped    = songset.loc[i,'category']\n",
    "        anime   = ValidFile(songset.loc[i,'anime'])\n",
    "        title   = ValidFile(songset.loc[i,'songname'].strip())\n",
    "        artist  = ValidFile(songset.loc[i,'artist'].strip())\n",
    "        path    = year + '/' + season + '/' + anime + '/' + oped + '/' + artist + '/'+ title\n",
    "        ffpath  = 'ffmpeg'\n",
    "        dlpath  = dl_loc +'/' + 'Animusic'\n",
    "        api1    = 'f2d89a80d48e41e19e4263d5b3792c21'\n",
    "        api2    = '12f6688e93504599b3d0403e8a4f2cc8'\n",
    "        logger  = Logger(log_location = dlpath, log_level = None)\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        print(i, path)\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        \n",
    "        #C:\\Users\\dell\\AppData\\Roaming\\Savify\\temp is where the temporary download goes\n",
    "        s = Savify(api_credentials  = (api1,api2), \n",
    "                    download_format = Format.MP3, \n",
    "                    ffmpeg_location = ffpath, \n",
    "                    skip_cover_art  = False, \n",
    "                    path_holder = PathHolder(downloads_path=dlpath), \n",
    "                    group   = path, \n",
    "                    quality = Quality.BEST,\n",
    "                    logger  = logger)\n",
    "        s.download(sp_link)\n",
    "        sheet_with_spotify.loc[i,'status'] = 'Downloaded'\n",
    "\n",
    "#downloads youtube video but sus \n",
    "def DownloadYoutube(sheet_with_youtube, dl_loc, start, end):\n",
    "    songset2 = sheet_with_youtube.loc[start:end,:]\n",
    "    for i in songset2.index:\n",
    "        if 'youtube' not in songset2.loc[i,'link'] or str(songset2.loc[i,'status']) == 'Downloaded' or str(songset2.loc[i,'status']) == 'sus': continue\n",
    "        year    = str(songset2.loc[i,'year'])\n",
    "        season  = str(songset2.loc[i,'season'])\n",
    "        anime   = songset2.loc[i,'anime']\n",
    "        oped    = songset2.loc[i,'category']\n",
    "        title   = songset2.loc[i,'songname']\n",
    "        artist  = songset2.loc[i,'artist']\n",
    "        yt_link = songset2.loc[i,'link']\n",
    "        path    = dl_loc + '/' + year + '/' + season + '/' + anime + '/' + oped + '/' + artist + '/'+ title + '/'\n",
    "        def my_hook(d):\n",
    "            if d['status'] == 'finished':\n",
    "                print('~~~~~~', i, title, artist,'~~~~~~')\n",
    "\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio',\n",
    "            'outtmpl': path + '%(title)s.%(ext)s',\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',}],\n",
    "                'progress_hooks': [my_hook]}\n",
    "\n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([yt_link])\n",
    "        sheet_with_youtube.loc[i,'status'] = 'Downloaded'\n",
    "    return sheet_with_youtube\n",
    "\n",
    "#Module 4: Playing with datasets to ensure youtube links are right\n",
    "#returns the 'dataset' set with indexes between 'start' and 'end' updated with the new 'status'\n",
    "def manual_status_update(dataset, start, end, status):\n",
    "    yt = pd.read_csv(dataset)\n",
    "    del yt['Unnamed: 0']\n",
    "    for i in range(start, end):\n",
    "        if yt.loc[i,'status'] == 'sus': continue\n",
    "        yt.loc[i,'status'] = status\n",
    "    return yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b9977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##converting xml to a csv with eligible anime and their mal links\n",
    "MakeCSV('mal_export.xml').to_csv('mal_to_csv_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e64055",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating a new csv of all songs and spotify links\n",
    "\n",
    "link_table = pd.DataFrame(columns = ['anime', 'season', 'year','category', 'songname', 'artist', 'link', 'status'])\n",
    "GetSpotify('mal_to_csv_filtered.csv', 956, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54856d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "##downloading songs from spotify\n",
    "\n",
    "dl_spot = pd.read_csv('sheet_w_spot.csv')\n",
    "#dl_spot = pd.read_csv('sheet_d_spot_w_yt.csv') #uncomment for reruns\n",
    "del dl_spot['Unnamed: 0']\n",
    " \n",
    "DownloadSpotify(dl_spot, 'D:/_Animusic/', 0, 0)\n",
    "dl_spot.to_csv('sheet_d_spot_w_yt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9336a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "##downloading all songs from youtube links\n",
    "yt = pd.read_csv('sheet_d_spot_s_yt.csv')\n",
    "#dl_spot = pd.read_csv('sheet_d_spot_d_yt.csv') #uncomment for reruns\n",
    "del yt['Unnamed: 0']\n",
    "DownloadYoutube(yt, 'F:/Animusic', 0, 50)\n",
    "yt.to_csv('sheet_d_spot_d_yt.csv')\n",
    "\n",
    "#manual_status_update('sheet_d_spot_d_yt.csv', 0, 13, 'Downloaded').to_csv('sheet_d_spot_d_yt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "69ee5a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>songname</th>\n",
       "      <th>artist</th>\n",
       "      <th>link</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-man no Inochi no Ue ni Ore wa Tatteiru</td>\n",
       "      <td>Fall 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>Opening Theme</td>\n",
       "      <td>Anti world</td>\n",
       "      <td>Kanako Takatsuki</td>\n",
       "      <td>https://open.spotify.com/track/47mtXCSExRrKA9c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-man no Inochi no Ue ni Ore wa Tatteiru</td>\n",
       "      <td>Fall 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>Ending Theme</td>\n",
       "      <td>Carpe・Diem (カルペ・ディエム)</td>\n",
       "      <td>Liyuu</td>\n",
       "      <td>https://open.spotify.com/track/2MtalMSV45ThxAF...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100-man no Inochi no Ue ni Ore wa Tatteiru 2nd...</td>\n",
       "      <td>Summer 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Opening Theme</td>\n",
       "      <td>Baddest</td>\n",
       "      <td>Kaede Higuchi (樋口楓)</td>\n",
       "      <td>https://open.spotify.com/track/0XMsMnaW0zceeFu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100-man no Inochi no Ue ni Ore wa Tatteiru 2nd...</td>\n",
       "      <td>Summer 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ending Theme</td>\n",
       "      <td>Subversive</td>\n",
       "      <td>Kanako Takatsuki (高槻かなこ)</td>\n",
       "      <td>https://open.spotify.com/track/1zJreL7IUwnJRBi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.43: Seiin Koukou Danshi Volley-bu</td>\n",
       "      <td>Winter 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Opening Theme</td>\n",
       "      <td>Mahi (麻痺)</td>\n",
       "      <td>yama</td>\n",
       "      <td>https://open.spotify.com/track/1LwSnnsoKcAUv9T...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>Zombieland Saga Revenge (Zombie Land Saga Reve...</td>\n",
       "      <td>Spring 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Opening Theme</td>\n",
       "      <td>Taiga yo Tomo ni Naitekure (大河よ共に泣いてくれ)</td>\n",
       "      <td>Fran Chou Chou (フランシュシュ) [Sakura Minamoto (Kae...</td>\n",
       "      <td>https://open.spotify.com/track/4DutefDeVcpLpBK...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>Zombieland Saga Revenge (Zombie Land Saga Reve...</td>\n",
       "      <td>Spring 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ending Theme</td>\n",
       "      <td>Revenge</td>\n",
       "      <td>FranChouChou (フランシュシュ) [Sakura Minamoto (Kaede...</td>\n",
       "      <td>https://open.spotify.com/track/3wO4w4AUnKGbENK...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>Zombieland Saga Revenge (Zombie Land Saga Reve...</td>\n",
       "      <td>Spring 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ending Theme</td>\n",
       "      <td>Kaze no Tsuyoi Hi wa Kirai ka? (FranChouChou c...</td>\n",
       "      <td>FranChouChou</td>\n",
       "      <td>https://open.spotify.com/track/2mk0CPKzVcusv5m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>Zombieland Saga Revenge (Zombie Land Saga Reve...</td>\n",
       "      <td>Spring 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ending Theme</td>\n",
       "      <td>Yume wo Te ni, Modoreru Basho mo Nai Hibi wo (...</td>\n",
       "      <td>Fran Chou Chou</td>\n",
       "      <td>https://open.spotify.com/track/5ETlRU6U6BloJC8...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>Zombieland Saga Revenge (Zombie Land Saga Reve...</td>\n",
       "      <td>Spring 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ending Theme</td>\n",
       "      <td>Mezame RETURNER (Electric Returner Type \"R\") (...</td>\n",
       "      <td>FranChouChou</td>\n",
       "      <td>https://open.spotify.com/track/7yAsWMCX5JOzkLy...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  anime       season  year  \\\n",
       "0            100-man no Inochi no Ue ni Ore wa Tatteiru    Fall 2020  2020   \n",
       "1            100-man no Inochi no Ue ni Ore wa Tatteiru    Fall 2020  2020   \n",
       "2     100-man no Inochi no Ue ni Ore wa Tatteiru 2nd...  Summer 2021  2021   \n",
       "3     100-man no Inochi no Ue ni Ore wa Tatteiru 2nd...  Summer 2021  2021   \n",
       "4                   2.43: Seiin Koukou Danshi Volley-bu  Winter 2021  2021   \n",
       "...                                                 ...          ...   ...   \n",
       "2285  Zombieland Saga Revenge (Zombie Land Saga Reve...  Spring 2021  2021   \n",
       "2286  Zombieland Saga Revenge (Zombie Land Saga Reve...  Spring 2021  2021   \n",
       "2287  Zombieland Saga Revenge (Zombie Land Saga Reve...  Spring 2021  2021   \n",
       "2288  Zombieland Saga Revenge (Zombie Land Saga Reve...  Spring 2021  2021   \n",
       "2289  Zombieland Saga Revenge (Zombie Land Saga Reve...  Spring 2021  2021   \n",
       "\n",
       "           category                                           songname  \\\n",
       "0     Opening Theme                                         Anti world   \n",
       "1      Ending Theme                              Carpe・Diem (カルペ・ディエム)   \n",
       "2     Opening Theme                                            Baddest   \n",
       "3      Ending Theme                                         Subversive   \n",
       "4     Opening Theme                                          Mahi (麻痺)   \n",
       "...             ...                                                ...   \n",
       "2285  Opening Theme            Taiga yo Tomo ni Naitekure (大河よ共に泣いてくれ)   \n",
       "2286   Ending Theme                                            Revenge   \n",
       "2287   Ending Theme  Kaze no Tsuyoi Hi wa Kirai ka? (FranChouChou c...   \n",
       "2288   Ending Theme  Yume wo Te ni, Modoreru Basho mo Nai Hibi wo (...   \n",
       "2289   Ending Theme  Mezame RETURNER (Electric Returner Type \"R\") (...   \n",
       "\n",
       "                                                 artist  \\\n",
       "0                                      Kanako Takatsuki   \n",
       "1                                                 Liyuu   \n",
       "2                                   Kaede Higuchi (樋口楓)   \n",
       "3                              Kanako Takatsuki (高槻かなこ)   \n",
       "4                                                  yama   \n",
       "...                                                 ...   \n",
       "2285  Fran Chou Chou (フランシュシュ) [Sakura Minamoto (Kae...   \n",
       "2286  FranChouChou (フランシュシュ) [Sakura Minamoto (Kaede...   \n",
       "2287                                       FranChouChou   \n",
       "2288                                     Fran Chou Chou   \n",
       "2289                                       FranChouChou   \n",
       "\n",
       "                                                   link  extra  \n",
       "0     https://open.spotify.com/track/47mtXCSExRrKA9c...    NaN  \n",
       "1     https://open.spotify.com/track/2MtalMSV45ThxAF...    NaN  \n",
       "2     https://open.spotify.com/track/0XMsMnaW0zceeFu...    NaN  \n",
       "3     https://open.spotify.com/track/1zJreL7IUwnJRBi...    NaN  \n",
       "4     https://open.spotify.com/track/1LwSnnsoKcAUv9T...    NaN  \n",
       "...                                                 ...    ...  \n",
       "2285  https://open.spotify.com/track/4DutefDeVcpLpBK...    NaN  \n",
       "2286  https://open.spotify.com/track/3wO4w4AUnKGbENK...    NaN  \n",
       "2287  https://open.spotify.com/track/2mk0CPKzVcusv5m...    NaN  \n",
       "2288  https://open.spotify.com/track/5ETlRU6U6BloJC8...    NaN  \n",
       "2289  https://open.spotify.com/track/7yAsWMCX5JOzkLy...    NaN  \n",
       "\n",
       "[2290 rows x 8 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Ensuring robustness for new database, i.e. everytime a new mal list is exported\n",
    "##How to introduce insert songs from sources other than mal?\n",
    "old = pd.read_csv('sheet_w_spot.csv', header = None)\n",
    "new = pd.read_csv('Older/sheet_w_spot.csv')\n",
    "new.drop('Unnamed: 0', inplace = True, axis = 1)\n",
    "old.columns = ['anime', 'season', 'year','category', 'songname', 'artist', 'link', 'status']\n",
    "\n",
    "new = new.drop_duplicates(subset = 'link', keep = 'first')\n",
    "\n",
    "'''\n",
    "for index, row in new.iterrows():\n",
    "    # Check if the combination of anime, songname, and artist match in the old DataFrame\n",
    "    match_condition = (old['anime'] == row['anime']) & (old['songname'] == row['songname']) & (old['artist'] == row['artist'])\n",
    "\n",
    "    # Check if the link is different in the new DataFrame\n",
    "    if match_condition.any() and row['link'] != '' and old.loc[match_condition, 'link'].values[0] != row['link']:\n",
    "        # Update the link in the old DataFrame\n",
    "        old.loc[match_condition, 'link'] = row['link']\n",
    "\n",
    "        # Check if the status column in the old DataFrame contains \"Downloaded\" and replace it with blank\n",
    "        if old.loc[match_condition, 'status'].values[0] == \"Downloaded\":\n",
    "            old.loc[match_condition, 'status'] = 'SEX'\n",
    "\n",
    "old.to_csv('We cooked.csv')'''\n",
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7bba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "22354d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard data has been appended to leaderboard_data.csv at 2023-10-03 20:20:54.\n"
     ]
    }
   ],
   "source": [
    "#pokefarm \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Initialize a dictionary to store user scores\n",
    "user_scores = {}\n",
    "\n",
    "# Function to scrape data and append to CSV\n",
    "def scrape_and_append_to_csv():\n",
    "    payload = {'inUserName': 'tanmayonnaise', 'inUserPass': '534519B4C10C03F2'}\n",
    "    url = 'https://pokefarm.com/stats/interactions'\n",
    "    html = requests.get(url, data=payload) #type: ignore\n",
    "\n",
    "    # Parse the HTML using BeautifulSoup\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "\n",
    "    # Find all the <li> elements within the <ol> with class \"leaderboard\"\n",
    "    leaderboard_items = soup.find_all('li')\n",
    "\n",
    "    # Get the current timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Loop through the <li> elements to update user scores\n",
    "    for item in leaderboard_items:\n",
    "        # Extract the user's name from the <a> element, accounting for both classes\n",
    "        user_link = item.find('a', class_='userlink0') or item.find('a', class_='userlink8')\n",
    "        user = user_link.text.strip() if user_link else \"\"\n",
    "\n",
    "        # Extract the user's score from the <span> element\n",
    "        score = item.find('span', class_='score').text.strip()\n",
    "\n",
    "        # Update the user's score in the dictionary\n",
    "        user_scores[user] = score\n",
    "\n",
    "    # Append the timestamp as a new column\n",
    "    user_scores[\"Timestamp\"] = timestamp\n",
    "\n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame([user_scores])\n",
    "\n",
    "    # Define the CSV file name\n",
    "    csv_file_name = \"leaderboard_data.csv\"\n",
    "\n",
    "    # Append the data to the existing CSV file, or create a new file if it doesn't exist\n",
    "    df.to_csv(csv_file_name, mode='a', header=False, index=False)\n",
    "    \n",
    "    print(f\"Leaderboard data has been appended to {csv_file_name} at {timestamp}.\")\n",
    "\n",
    "# Run the code to scrape and append data to CSV\n",
    "scrape_and_append_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4c367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3a52463084db90f96d29dcfcfd9bf276dba3c521d76c4c38c835392b64a093b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
